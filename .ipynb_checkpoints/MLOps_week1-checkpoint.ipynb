{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44104f7",
   "metadata": {},
   "source": [
    "### Introduction to MLOps\n",
    "* Overview\n",
    "  + rule of 25\n",
    "    + 25% effort goes to DevOps\n",
    "    + 25% effort goes to data operations to automate data\n",
    "    + 25% effort goes to modeling and improving modeling\n",
    "    + 25% effort goes to framing or looking at business requirements\n",
    "  + Trends and techniques\n",
    "    + production first mindset\n",
    "      + everything related to the product system needs to be automated\n",
    "* what is devops: combination of \n",
    "  + checklist of software engineering best practice\n",
    "  + culture of continuous improvement\n",
    "  + CI/CD, infrastructure as a code for automation\n",
    "* DataOps\n",
    "  + apply the same principles of devops to data and data systems\n",
    "  + constantly make improvements (data more cleaner)\n",
    "  \n",
    "* cloud programming on github codebase environment\n",
    "  + set up virtual environment by \n",
    "  `virtualenv ~/.venv\n",
    "    source ~/.venv/bin/activate`\n",
    "  + set up the reference to the virtual environment by`vim ~/.bashrc`\n",
    "    + shift g to go to the end of the file, and add `source ~/.venv/bin/activate`\n",
    "  + create Makefile by `touch Makefile`\n",
    "  + create requirments.txt by `touch requirements.txt`\n",
    "  + create a python file such as hello.py and its test file `test_hello.py`\n",
    "  + scafold of Makefile\n",
    "  ```Shell\n",
    "  install:\n",
    "    pip install --upgrade pip &&\\\n",
    "        pip install -r requirements.txt\n",
    "        \n",
    "  test:\n",
    "    python -m pytest -vv test_hello.py\n",
    "    \n",
    "  format:\n",
    "    black *.py\n",
    "    \n",
    "  lint:\n",
    "    pylint --disable=R, C hello.py\n",
    "    \n",
    "  all: install lint test format\n",
    "  ```\n",
    " + requirements.txt\n",
    "  `pytest\n",
    "   pytest-cov\n",
    "   pylint\n",
    "   black\n",
    "   ipython`\n",
    "   \n",
    " + using ipython as a debug tool for your code  \n",
    "   + activate ipython by typing ipython in terminal\n",
    "   + import the function you want to check by `from hello import more_hello` where hello is the .py file and `more_hello` is the function in the file\n",
    "     + you can use pytest grammar such as `assert \"h1\" == more_hello()` "
   ]
  },
  {
   "cell_type": "raw",
   "id": "11e196cb",
   "metadata": {},
   "source": [
    "# template for github actions\n",
    "# in actions part, select \"set up your own workflow\", and use the template\n",
    "# give the file a name. Click \"start commit\" to run the pipeline\n",
    "name: Python application test with Github Actions\n",
    "\n",
    "on: [push]\n",
    "\n",
    "jobs:\n",
    "  build:\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    - name: Set up Python 3.8\n",
    "      uses: actions/setup-python@v1\n",
    "      with:\n",
    "        python-version: 3.8\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        make install\n",
    "    - name: Lint with pylint\n",
    "      run: |\n",
    "        make lint\n",
    "    - name: Test with pytest\n",
    "      run: |\n",
    "        make test\n",
    "    - name: Format code\n",
    "      run: |\n",
    "        make format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c090f6",
   "metadata": {},
   "source": [
    "### Continuous Delivery (CD)\n",
    "* use a cloud native environment can provide a similar environment to your prod system\n",
    "* you push the code and Infrastructure as code (IAC) to the cloud environment to provision the resources and change code\n",
    "* source control repo will trigger build system component to test the code and merge code\n",
    "* build system will then create/mutate/delete infrastructure (IAC) will make sure the states of infrastructure is idempotent\n",
    "\n",
    "### Feature Store\n",
    "* data warehouse vs feature store\n",
    "  + data lake contains raw data including a variety of source data, such as streaming data, batch data, structured and unstructured data\n",
    "  + one way to use the data is the featurization that transform the data to reusable, high quality ML inputs in feature store\n",
    "    + the high quality data in feature store can be used to train models and make predictions, being audited and extract relationships between features\n",
    "  + another way is to use ETL to transform data data in data warehouse as reusable, high-quality BI inputs for building reporting, dashboards and BI systems\n",
    "  \n",
    "### Data Drift\n",
    "* when data drifts constantly, it is difficult to build an efficient model. Therefore, retraining the model is usually necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81535c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
