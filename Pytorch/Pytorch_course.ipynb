{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757942ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2202da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3c0ee",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "### Typical tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d46c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_array = torch.Tensor([[1,2], [4,5]])\n",
    "tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2609571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uninitialized tensor (can not be accessed)\n",
    "tensor_uninitialized = torch.Tensor(3, 3)\n",
    "torch.numel(tensor_uninitialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ad21ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3708, 0.3674, 0.3466],\n",
       "        [0.2919, 0.3940, 0.0095]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a tensor with torch.rand for float\n",
    "tensor_initialized = torch.rand(2, 3)\n",
    "tensor_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33d5d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0, -1,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can define the data type when initializing\n",
    "tensor_int = torch.randn(5, 3).type(torch.IntTensor)\n",
    "tensor_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82cf259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define long int tensors\n",
    "tensor_long = torch.LongTensor([1.0, 2.0, 3.0])\n",
    "tensor_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d40b67e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 127,   1, 251], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define byte tensors\n",
    "tensor_byte = torch.ByteTensor([0, 127, 1, -5])\n",
    "tensor_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a795c56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize tensor with 1s\n",
    "tensor_ones = torch.ones(10)\n",
    "tensor_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a6e3520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize tensor with 0s\n",
    "tensor_zeros = torch.zeros(10)\n",
    "tensor_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff2e3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize tensor with diagno matrix\n",
    "tensor_eye = torch.eye(3)\n",
    "tensor_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214b5577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nonzero function returns the positions of all nonzero elements\n",
    "non_zero = torch.nonzero(tensor_eye)\n",
    "non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f5ded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor with all 1s and the same shape as another tensor\n",
    "# the output tensor has the same shape as tensor_eye with all 1s\n",
    "tensor_ones_shape_eye = torch.ones_like(tensor_eye)\n",
    "tensor_ones_shape_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314a236c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in place operations. all in place function has _suffix\n",
    "initial_tensor = torch.rand(3, 3)\n",
    "initial_tensor.fill_(3) # fill elements by value of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d1cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7.],\n",
       "        [7., 7., 7.],\n",
       "        [7., 7., 7.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of place operation will create and return a new tensor\n",
    "new_tensor = initial_tensor.add(4)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26bec3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c686716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in place add_ oprator changes the value in place\n",
    "initial_tensor.add_(5)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd829f",
   "metadata": {},
   "source": [
    "### Tensor operations with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5fb48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7940a2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr = np.array([1, 2, 3])\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf5e238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy array to tensor\n",
    "tensor = torch.from_numpy(numpy_arr)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68dd5715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor to numpy array\n",
    "numpy_from_tensor = tensor.numpy()\n",
    "numpy_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84de49dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor and np array share the same memory\n",
    "# change one will change another\n",
    "numpy_arr[1] = 4\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9622c831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998ce3c",
   "metadata": {},
   "source": [
    "### Access tensor elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dcffb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1482, 0.1976, 0.5693],\n",
       "        [0.2040, 0.3582, 0.7984]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by dimension indices\n",
    "initial_tensor = torch.rand(2, 3)\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcd279c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5693)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select by element index\n",
    "initial_tensor[0, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29c176da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1976, 0.5693],\n",
       "        [0.3582, 0.7984]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select subset of elemens by slicing\n",
    "initial_tensor[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0351de2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a view that share the same memory as original tensor\n",
    "# the view have differnt dimensions from the original tensor\n",
    "resized_tensor = initial_tensor.view(6)\n",
    "resized_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "098febdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tensor[0, 2] = 0.111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97cca2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1482, 0.1976, 0.1110, 0.2040, 0.3582, 0.7984])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the resized_tensor flattern the initial_tensor to 1d\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91297b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1482, 0.1976],\n",
       "        [0.1110, 0.2040],\n",
       "        [0.3582, 0.7984]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize anoter view of the tensor\n",
    "resized_tensor = initial_tensor.view(3, 2)\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccea61a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1482, 0.1976],\n",
       "        [0.1110, 0.2040],\n",
       "        [0.3582, 0.7984]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pytorch to infer the dimension using -1\n",
    "resized_matrix = initial_tensor.view(-1, 2)\n",
    "resized_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d46c9e",
   "metadata": {},
   "source": [
    "### Getting tensor dimension by size() and shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f8bb842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e75bb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f46d2b",
   "metadata": {},
   "source": [
    "### Sort tensor values and sorted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7f801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1482, 0.1976, 0.1110],\n",
       "        [0.2040, 0.3582, 0.7984]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af104862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort tensor elements by row (dim=1)\n",
    "sorted_tensor, sorted_indices = torch.sort(initial_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "882e1cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1110, 0.1482, 0.1976],\n",
       "        [0.2040, 0.3582, 0.7984]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f3219da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 1],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0b40e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort tensor by columns using dim = 0\n",
    "sorted_tensor, sorted_tensor_indices = torch.sort(initial_tensor, dim= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "272b2d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1482, 0.1976, 0.1110],\n",
       "        [0.2040, 0.3582, 0.7984]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ba6a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b113d0e",
   "metadata": {},
   "source": [
    "### Computation Graph\n",
    "* in pytorch, it is dynamic\n",
    "* everything you set up in deep learning is a computation graph\n",
    "* tensorflow runs in \"Define, then run\" philosophy\n",
    "  + you first build a graph that specifies the operations and the data\n",
    "  + then you run the graph by executing the graph to get the final result\n",
    "* pytorch follows the \"define by run\"\n",
    "  + when building the graph, it allows you to run the graph\n",
    "  + build and execute the graph in one go - execute as you build\n",
    "*   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c159344b",
   "metadata": {},
   "source": [
    "### Summary of Pytorch\n",
    "* PyTorch is a deep learning framework\n",
    "* More tightly integrated wit Python than Tensorflow\n",
    "* Can use other python libraries, debugger\n",
    "* Supports dynamic computation graphs, update the graph for each epoch\n",
    "* Uses a forward pass for prediction, backward pass to update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0e5b5",
   "metadata": {},
   "source": [
    "## Simple Neural Networks\n",
    "\n",
    "### Autograd\n",
    "* Pytorch uses the Autograd library for backprogagation during training\n",
    "* Autograd relies on reverse-mode automatic differentiation\n",
    "* Conceptually similar to autodiff in TensorFlow\n",
    "* NLL as loss function and LogSoftMax as output layer\n",
    "\n",
    "### Metric used to train model\n",
    "* Mean square Error (MSE) is the metric to be minimized during training of regression model\n",
    "* Mean square error more specificall is Mean Square Error of Loss, where Loss is the difference between predicted and actural\n",
    "\n",
    "### Calculate Gradients\n",
    "* Symbolic differentiation\n",
    "  + conceptually simple but hard to implement\n",
    "* numeric differentiation\n",
    "  + easy to implement but won't scale\n",
    "* automatic differentiation\n",
    "  + conceptually difficult but easy to implement\n",
    "  + Pytorch, TensorFlow and other packages rely on automatic differentiation\n",
    "  + relies on a mathematical trick based on Taylor's Series Expansion that allows fast approximation of gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea300318",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "* the PyTorch package for calculating gradients for back progagation\n",
    "* Autograd is a core package for automatic differentiation\n",
    "* It remembers all executed operations in the forward phase and replays them in the backward phase\n",
    "\n",
    "#### Properties of tensors\n",
    "* every tensor has requires_grad property to define if the tensor will be tracked for backpropagation\n",
    "* you set requires_grad by requires_grad_() function\n",
    "* every tensor has grad property, which is a tensor that accumulates the gradient of the computations w.r.t this tensor after the backeward pass\n",
    "* every tensor has grad_fn, that defines the gradient function\n",
    "* both grad and grad_fn will be None until you calculate the backward gradient in a graph\n",
    "* If the tensors in the computation have requires_grad = True the computed output will be true as well\n",
    "* to stop autograd from tracking history on newly created tensors, use with torch.no_grad(): context manager\n",
    "  + tensors created in this context manager will not track its grad property, and requires_grad is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ecc22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [7., 5.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo code of autograd\n",
    "\n",
    "tensor = torch.Tensor([[3, 4],\n",
    "                       [7, 5]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee469d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad defines if the computation by this\n",
    "# tensor will be tracked by autograd package\n",
    "tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "905caf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to set requires_grad to true so that the calculation\n",
    "# can be tracked for gradient calculaton, use requrires_grad_()\n",
    "tensor.requires_grad_()\n",
    "tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e834900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "985ba406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82bb5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (tensor * tensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5a81424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e667783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HuangY07\\AppData\\Local\\Temp\\1\\ipykernel_24636\\4162821179.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:491.)\n",
      "  print(out.grad)\n"
     ]
    }
   ],
   "source": [
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "192a5bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6dc811c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward0 object at 0x00000207C816A950>\n"
     ]
    }
   ],
   "source": [
    "# we have a gradient function associated with the out tensor\n",
    "# becuase out is the result of a computation\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dbf85341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 2.0000],\n",
      "        [3.5000, 2.5000]])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HuangY07\\AppData\\Local\\Temp\\1\\ipykernel_24636\\3721122271.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:491.)\n",
      "  print(out.grad)\n"
     ]
    }
   ],
   "source": [
    "# if we calculate the backward path of out\n",
    "# we will have its grad tensor to store the accumulated backward grad\n",
    "# whenever we calculate out.backward, all tensors on its path will have grad calculated\n",
    "out.backward()\n",
    "print(tensor.grad)\n",
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e55d79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 2.0000],\n",
      "        [3.5000, 2.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d877e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# since tensor has requires_grad as true, any computed output will have requires_grad as true\n",
    "new_tensor = tensor * tensor\n",
    "print(new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc86515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor = tensor([[ 9., 16.],\n",
      "        [49., 25.]])\n",
      "requires_grad for tensor = True\n",
      "requires_grad for new_tensor = False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # since new_tensor is created in the context manager, its grad will not be tracked\n",
    "    new_tensor = tensor * tensor\n",
    "    print(f'new_tensor = {new_tensor}')\n",
    "    print(f'requires_grad for tensor = {tensor.requires_grad}')\n",
    "    print(f'requires_grad for new_tensor = {new_tensor.requires_grad}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57487d0",
   "metadata": {},
   "source": [
    "### Reverse auto-differentiation\n",
    "* back progagation is implemented using a technique called reverse auto-differentiation\n",
    "  + calcualte gradients used to update the model parameters \n",
    "* reverse-mode auto-differentiation is used in tensorflow and pytorch\n",
    "* two passes are required in each training step\n",
    "  + forward step to calculate loss\n",
    "  + backward step to calucate grad and update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9dd897",
   "metadata": {},
   "source": [
    "### Demonstration of Linear Model using Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
